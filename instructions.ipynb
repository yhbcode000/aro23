{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d252d842",
   "metadata": {},
   "source": [
    "# Table Of Content:\n",
    "* Preliminaries\n",
    "    * [Structure of the lab](#structure)\n",
    "    * [Objective of the lab](#objective)\n",
    "    * [How to work for the lab?](#howto)\n",
    "    * [Setting up the scene](#scene)\n",
    "* [Part 1: Geometry](#part1)\n",
    "    * [I. Computing the target configurations (Inverse Geometry)](#IG)\n",
    "    * [II. Motion planning](#motion_planning)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a061912f",
   "metadata": {},
   "source": [
    "# Structure of the lab:  <a class=\"anchor\" id=\"structure\"></a>\n",
    "The lab is divided into separate python files, each designed for you to address a sub-problem atomically. These instructions will indicate where you should implement each task. At the end of each file, in the 'main' \n",
    "section you can locally test your functions. It is important that you **do not modify the names and signatures** of the methods provided: When marking the lab, I will in first instance run code that will use these functions to evaluate quantitatively the methods you proposed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d24413",
   "metadata": {},
   "source": [
    "# Objective of the lab <a class=\"anchor\" id=\"objective\"></a>\n",
    "Use both effectors of the nextage robot to grab a box and bring it to a target location.\n",
    "You will first plan a valid motion that brings the robot to a grasping configuration, then moves the box to \n",
    "a desired location while avoiding collisions. For this you will use a combination of motion planning and numerical optimisation.\n",
    "\n",
    "Once this motion plan will be computed, you will test it in a dynamics simulator using a control method of your choice.\n",
    "This will be the objective of part 2 of the lab.\n",
    "\n",
    "In the optional part 3 of the lab (for exceptional marks), you will be asked to self-propose a more complex task to achieve, which will require you to implement additional features to your framework. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1d1455",
   "metadata": {},
   "source": [
    "# How to work for the lab? <a class=\"anchor\" id=\"howto\"></a>\n",
    "You have been used to notebooks for the tutorials, and these instructions also take the form of a notebook. To implement this lab I personally chose to work directly with a python IDE and I recommend to do the same. I worked with spyder but any python IDE might work as well. You can decide to work using notebooks if you prefer, this is not a problem, as long as your final deliverables meet the requirement specification.\n",
    "\n",
    "**In any case, keep your code in a versioning system**. You are free to use github gitlab or whatever service you are more comfortable working with. The easiest way to work is to \"fork\" the lab repository from github into your own account and adding this new repository as a remote server.\n",
    "\n",
    "\n",
    "\n",
    "## Code production\n",
    "You are free to reuse code from the tutorials or any other source as long as you explicitely **cite its origin both in the code and in your report**. You are free to use any method from the pinocchio API and to create as many methods as you would like. **If you want to use non-native python libraries**, we must discuss this. Remember that I will have to run your code to assess your lab!\n",
    "\n",
    "\n",
    "## I don't like the approach you have proposed to solve the problem. Can I do my own thing?\n",
    "Yes... and no. First of all, I would suggest that you discuss this with the TAs / myself before going for it. Secondly, you will see in the submission requirements that I only need some methods to be implemented for me to assess quantitatively your work. I consider that if all of these methods are implemented you followed the instructions. The report will then give you a chance to justify your approach. This should give you a lot of freedom. In particular at step 2 I propose to use motion planning to compute a reference path for the robot. If you choose a different approach it does not matter to me as long as we discussed it before and that it is not hard-coded somehow. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da0e38c",
   "metadata": {},
   "source": [
    "# Setting up the scene <a class=\"anchor\" id=\"scene\"></a>\n",
    "\n",
    "To ensure efficient use of resources and to prevent the unintentional creation of multiple Meshcat server instances, I recommend initializing the server through the command line. Here's how you can do it:\n",
    "\n",
    "- Open a terminal. If you're on Ubuntu, you can quickly do this by pressing `ctrl + alt + t`.\n",
    "- Enter the following command and press `Enter`:\n",
    "   ```\n",
    "   meshcat-server \n",
    "   ```\n",
    "- Upon running the command, you'll receive an output that includes the \"zmq_url\". This is the address to which you will connect.\n",
    "\n",
    "**Tip**: You can run terminal commands directly from the Jupyter Notebook by prefixing them with `!`. However, for the purpose of this lab, I recommend initializing the Meshcat server directly from the terminal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cfdd871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !meshcat-server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb4d8dc",
   "metadata": {},
   "source": [
    "A helper function has been implemented to automatically connect to meshcat server, load the scene and the robot, and setup the collision handler in pinocchio for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60f7a783",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Aug 23 2023 13:25:42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapper tries to connect to server <tcp://127.0.0.1:6000>\n",
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7000/static/\n"
     ]
    }
   ],
   "source": [
    "from tools import setupwithmeshcat\n",
    "robot, cube, viz = setupwithmeshcat(url=\"tcp://127.0.0.1:6000\")\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b84c85f",
   "metadata": {},
   "source": [
    "```setupwithmeshcat``` takes an optional parameter corresponding to the url (zmq_url) of the meshcat server (given as a string). If no url is provided, it uses the variable ```MESHCAT_URL``` defined in config.py . If for some reason the default url does not match the one you are using, you can either provide this url to ```setupwithmeshcat``` or simply replace the value of ```MESHCAT_URL```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a3385f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tcp://127.0.0.1:6000\n"
     ]
    }
   ],
   "source": [
    "from config import MESHCAT_URL\n",
    "print(MESHCAT_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f37692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"height: 400px; width: 100%; overflow-x: auto; overflow-y: hidden; resize: both\">\n",
       "            <iframe src=\"http://127.0.0.1:7000/static/\" style=\"width: 100%; height: 100%; border: none\"></iframe>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(viz.viewer, 'jupyter_cell') and viz.viewer.jupyter_cell()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1784092",
   "metadata": {},
   "source": [
    "## Description of the environment.\n",
    "The environment is composed of a fixed table and an obstacle, as well as a cube, which you are supposed to bring \n",
    "to the green target.\n",
    "\n",
    "## Description of the robot. \n",
    "The robot you will use for the lab is the Nextage robot from Kawada industries.\n",
    "You can use both pinocchio and the URDF files (in TODO) to check the dimension of the robot configuration space.\n",
    "The configuration velocity space has the same dimension as Nextage is only composed of revolute joints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953a9d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb joints = 16 (nq=15,nv=15)\n",
      "  Joint 0 universe: parent=0\n",
      "  Joint 1 CHEST_JOINT0: parent=0\n",
      "  Joint 2 HEAD_JOINT0: parent=1\n",
      "  Joint 3 HEAD_JOINT1: parent=2\n",
      "  Joint 4 LARM_JOINT0: parent=1\n",
      "  Joint 5 LARM_JOINT1: parent=4\n",
      "  Joint 6 LARM_JOINT2: parent=5\n",
      "  Joint 7 LARM_JOINT3: parent=6\n",
      "  Joint 8 LARM_JOINT4: parent=7\n",
      "  Joint 9 LARM_JOINT5: parent=8\n",
      "  Joint 10 RARM_JOINT0: parent=1\n",
      "  Joint 11 RARM_JOINT1: parent=10\n",
      "  Joint 12 RARM_JOINT2: parent=11\n",
      "  Joint 13 RARM_JOINT3: parent=12\n",
      "  Joint 14 RARM_JOINT4: parent=13\n",
      "  Joint 15 RARM_JOINT5: parent=14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(robot.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019167b4",
   "metadata": {},
   "source": [
    "You can also verify that in its default configuration the robot is in collision (with the table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d35965de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools import collision\n",
    "collision(robot, robot.q0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa20b41",
   "metadata": {},
   "source": [
    "# Configuration and helper functions  <a class=\"anchor\" id=\"config\"></a>\n",
    "\n",
    "I have modified the URDF files to add frames that are relevant for the tasks you need to accomplish.\n",
    "On the robot, I have created fixed joints attached to the tip of each effectors, called ```LARM_EFF``` and ```RARM_EFF```. Note that because they are fixed joints, they do not appear in the robot model and do not change the dimension of the configuration space. These names are defined for you in the config.py file as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a389c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47f46aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left hand joint name:  LARM_EFF\n",
      "Left hand joint placement: \n",
      "  R =\n",
      "-3.67321e-06           -1            0\n",
      "           1 -3.67321e-06            0\n",
      "           0            0            1\n",
      "  p = 0.452  0.28 0.851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from config import LEFT_HAND, RIGHT_HAND\n",
    "\n",
    "print (\"Left hand joint name: \", LEFT_HAND)\n",
    "\n",
    "\n",
    "import pinocchio as pin\n",
    "q = robot.q0.copy()\n",
    "\n",
    "#update the frame positions in robot.data given q\n",
    "pin.framesForwardKinematics(robot.model,robot.data,q)\n",
    "\n",
    "#now let's print the placement attached to the right hand\n",
    "print (\"Left hand joint placement: \")\n",
    "pin.computeJointJacobians(robot.model,robot.data,q)\n",
    "frameid = robot.model.getFrameId(LEFT_HAND)\n",
    "oMframe = robot.data.oMf[frameid] \n",
    "print(oMframe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dd8e66",
   "metadata": {},
   "source": [
    "Likewise the cube urdf (models/cubes/cube_small.urdf) also contains helpers joint that set a target location for the effectors. They are called ```LEFT_HOOK``` and ```RIGHT_HOOK``` in config.py.\n",
    "\n",
    "I added meshcat helper functions that will allow you to display the associated frames if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ba2ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import LEFT_HOOK, RIGHT_HOOK, CUBE_PLACEMENT, CUBE_PLACEMENT_TARGET\n",
    "\n",
    "from tools import getcubeplacement, setcubeplacement\n",
    "from setup_meshcat import updatevisuals\n",
    "\n",
    "#We can access the current cube position using\n",
    "oMcube  = getcubeplacement(cube) #origin of the cube\n",
    "oMcubeL = getcubeplacement(cube, LEFT_HOOK) #placement of the left hand hook\n",
    "oMcubeR = getcubeplacement(cube, RIGHT_HOOK) #placement of the right hand hook\n",
    "\n",
    "\n",
    "#the cube position is updated using the following function:\n",
    "setcubeplacement(robot, cube, CUBE_PLACEMENT)\n",
    "#to update the frames for both the robot and the cube you can call\n",
    "updatevisuals(viz, robot, cube, q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23849de9",
   "metadata": {},
   "source": [
    "# Part 1: Geometry <a class=\"anchor\" id=\"part1\"></a>\n",
    "In this first part of the lab, we are concerned with the geometry of the robot and in motion planning in general.\n",
    "We are going to compute a geometric path that will serve as a guide for the dynamic part. Concretely, your objective is to compute a collision free path for the robot such that it \"grasps\" the cube and carries it over to its target position. Again, no dynamic computations are required in this phase, we are only interested in configurations that should be collision free, respect joint limits and geometrically consistent in terms of placement; there is already some work to be done here!\n",
    "\n",
    "## I. Computing the target configurations (Inverse Geometry) <a class=\"anchor\" id=\"IG\"></a>\n",
    "\n",
    "Your first task is the following: write the functions that generate an initial and a goal configuration for the nextage robot, such that the ```LEFT_HAND``` and ```RIGHT_HAND```are aligned respectively with the ```LEFT_HOOK``` and ```RIGHT_HOOK``` frames when the cube is located at its starting position  (```CUBE_PLACEMENT```) and at its goal position (```CUBE_PLACEMENT_TARGET```)\n",
    "\n",
    "For this implement the method ```computeqgrasppose``` in inverse_geometry.py \n",
    "\n",
    "The main method indicates how the method is going to be called to obtain the q0 and qe configurations:\n",
    "```\n",
    "q0 = computeqgrasppose(robot, q, cube, CUBE_PLACEMENT, viz)\n",
    "qe = computeqgrasppose(robot, q, cube, CUBE_PLACEMENT_TARGET,  viz)\n",
    "```\n",
    "\n",
    "Of course, q0 and qe should be collision-free and respect the joint limits of the robot. Do not hard-code anything here. In my tests I will use different targets to test the generality of ```computeqgrasppose```.\n",
    "\n",
    "q0 should look somehow like this:\n",
    "<img src=\"./images/q0.png\" alt=\"drawing\" width=\"200\"/>\n",
    "\n",
    "\n",
    "\n",
    "**hints:** \n",
    "* If your configurations look unnatural, you probably want to somehow introduce a \"postural bias\" in whatever method you are using \n",
    "* From the obtained configurations, you can easily obtain the relative placement between both hands expressed in a specific frame. This might prove relevant later in the lab so you may want to store it somewhere (maybe in solution.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbf350c",
   "metadata": {},
   "source": [
    "## II. Motion planning <a class=\"anchor\" id=\"motion_planning\"></a>\n",
    "\n",
    "For section II, I am proposing one course of action to successfully achieve the planning of a motion such that the robot carries the cube from its initial configuration to the end configuration. You are free to choose another course of action, but I do not advise it unless you really know what you are doing. In any case talk to me before making that decision. No matter what approach you choose, the method ```computepath``` from path.py must be implemented as specified for you to get the points.\n",
    "\n",
    "To compute a geometric path that represents a collision-free motion of our robot carrying the cube from q0 to qe, I suggest to use a sampling based motion planner. \n",
    "\n",
    "We will use the path.py file to write the motion planning algorithm\n",
    "\n",
    "### II.a Sampling configurations\n",
    "To generate configurations for the planner, I suggest a 2 step process: randomly sample configurations for the cube, then solve an inverse geometry problem to generate a valid pose on that location. Of course, check that the joint limits are respected and the configuration is collision-free before returning it.\n",
    "\n",
    "**hint:** you are free to bound your problem by ensuring that the cube placements that you generate only occur at positions / orientations that you think are interesting.\n",
    "\n",
    "### II.b Path projection\n",
    "However to do this we need to enforce the constraint that every sampled configuration is such that the effectors are holding the cube.\n",
    "\n",
    "Furthermore, the grasping constraint will apply to the complete path: a standard linear interpolation between two grasping configurations is not enough to guarantee that every interpolated configuration is such that the cube is grasped.\n",
    "Write a function that, given two configurations q0 and q1 and a discretisation step, returns an interpolated path between q0 and q1 such that every configuration in the path corresponds to a grasping pose. If it is not possible to generate such path, it will return a flag indicating so and, depending on your own decision, either return the part of the path that is valid, or nothing\n",
    "\n",
    "### II.c Solution path generation\n",
    "With the methods produced in II.1 and II.2, you should now be able to implement a motion planner that generates a geometrically valid path between q0 and qe. You can probably reuse code from the motion planning tutorial here, or implement you own. \n",
    "\n",
    "**requirement:** For me to assess this part you are required to implement the method ```computepath``` according to its documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c3564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
